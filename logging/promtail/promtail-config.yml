# Promtail Configuration - Production Best Practices
# Collects logs from Docker containers via Docker socket

server:
  http_listen_port: 9080
  grpc_listen_port: 0
  log_level: warn

positions:
  filename: /promtail/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push
    batchwait: 1s
    batchsize: 1048576  # 1MB
    timeout: 10s
    backoff_config:
      min_period: 500ms
      max_period: 5m
      max_retries: 10

scrape_configs:
  - job_name: docker
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 15s  # Reduced from 5s to lower overhead
        filters:
          # Only collect logs from our app containers
          - name: label
            values: ["app=trung-dev"]

    relabel_configs:
      # Extract container name
      - source_labels: ['__meta_docker_container_name']
        regex: '/(.*)'
        target_label: container

      # Extract environment label
      - source_labels: ['__meta_docker_container_label_environment']
        target_label: environment

      # Extract service name from container name
      - source_labels: ['__meta_docker_container_name']
        regex: '/django-(.+)-container'
        target_label: service

      # Drop tailwind and redis logs (not useful)
      - source_labels: ['__meta_docker_container_name']
        regex: '.*-(tailwind|redis)-.*'
        action: drop

      # Set the log path
      - source_labels: ['__meta_docker_container_id']
        target_label: __path__
        replacement: '/var/lib/docker/containers/$1/$1-json.log'

    pipeline_stages:
      # Parse Docker JSON log format
      - docker: {}

      # Parse JSON logs from Django (pythonjsonlogger format)
      - match:
          selector: '{service="blog"}'
          stages:
            - json:
                expressions:
                  level: levelname
                  timestamp: asctime
                  logger: name
                  message: message
            - labels:
                level:
                logger:
            - timestamp:
                source: timestamp
                format: RFC3339

      # Parse JSON logs from Nginx
      - match:
          selector: '{service="blog-nginx"}'
          stages:
            - json:
                expressions:
                  level: level
                  timestamp: timestamp
                  service: service
                  message: message
                  method: context.method
                  path: context.path
                  status_code: context.status_code
                  request_time: context.request_time
            - labels:
                level:
                method:
                status_code:
            - timestamp:
                source: timestamp
                format: RFC3339

      # Drop health check and static file logs from nginx
      - match:
          selector: '{service="blog-nginx"}'
          stages:
            - drop:
                expression: '.*(health|/static/|/favicon.ico).*'
                drop_counter_reason: noise

      # Drop flower periodic logs
      - match:
          selector: '{service="flower"}'
          stages:
            - drop:
                expression: '.*(Periodic|inspect).*'
                drop_counter_reason: periodic_noise

      # Drop celery heartbeat logs
      - match:
          selector: '{service=~"celery-worker|celery-beat"}'
          stages:
            - drop:
                expression: '.*(heartbeat|Scheduler|DatabaseScheduler: Schedule changed).*'
                drop_counter_reason: heartbeat_noise

      # Drop /metrics requests (Prometheus scrapes every 30s)
      - match:
          selector: '{service="blog"}'
          stages:
            - drop:
                expression: '.*GET /metrics.*'
                drop_counter_reason: prometheus_metrics

      # Drop redundant Gunicorn booting logs
      - match:
          selector: '{service="blog"}'
          stages:
            - drop:
                expression: '^\[\d{4}-\d{2}-\d{2}.*\] \[\d+\] \[INFO\] (Booting worker|Listening at|Using worker|Arbiter booted).*'
                drop_counter_reason: gunicorn_default_info

      # Add static labels
      - static_labels:
          app: trung-dev
          stack: django-blog

  # SeaweedFS logs from Ubuntu server filesystem (COMMENTED - uncomment and configure)
  # Prerequisites:
  #   1. Replace /seaweedfs/log/path with actual path (e.g., /var/log/seaweedfs/)
  #   2. Add volume mount in docker-compose.logging.yml:
  #      volumes:
  #        - /seaweedfs/log/path:/seaweedfs-logs:ro
  #   3. Ensure Promtail container has read permissions
  # - job_name: seaweedfs
  #   static_configs:
  #     - targets:
  #         - localhost
  #       labels:
  #         job: seaweedfs
  #         service: seaweedfs
  #         environment: production
  #         __path__: /seaweedfs-logs/*.log
  #
  #   pipeline_stages:
  #     # Parse SeaweedFS plain text logs
  #     # Format: [timestamp] [level] message
  #     - regex:
  #         expression: '^\[(?P<timestamp>.*?)\] \[(?P<level>\w+)\] (?P<message>.*)'
  #     - labels:
  #         level:
  #     - timestamp:
  #         source: timestamp
  #         format: '2006/01/02 15:04:05'  # Adjust based on actual SeaweedFS log format
  #     - static_labels:
  #         app: trung-dev
  #         stack: django-blog
